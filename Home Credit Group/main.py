import pandas as pd
import numpy as np
import xgboost as xgb

from functools import reduce
from abc import ABCMeta, abstractclassmethod
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from utils import *

# In the future, FEATURE_FILE_LIST will be generated by a web-app
FEATURE_FILE_LIST = [
    {'file': 'data/application_train.csv',
     'target': 'TARGET',
     'features': [
         {'column_name': 'SK_ID_CURR', 'dtype': 'int'},
         {'column_name': 'NAME_CONTRACT_TYPE', 'dtype': 'category'},
         {'column_name': 'CODE_GENDER', 'dtype': 'category'},
         {'column_name': 'CNT_CHILDREN', 'dtype': 'int'},
         {'column_name': 'NAME_INCOME_TYPE', 'dtype': 'category'},
         {'column_name': 'NAME_EDUCATION_TYPE', 'dtype': 'category'},
         {'column_name': 'NAME_HOUSING_TYPE', 'dtype': 'category'},
         {'column_name': 'DAYS_EMPLOYED', 'dtype': 'int'},
         {'column_name': 'DAYS_REGISTRATION', 'dtype': 'int'},
         {'column_name': 'DAYS_ID_PUBLISH', 'dtype': 'int'},
         {'column_name': 'OWN_CAR_AGE', 'dtype': None},
         {'column_name': 'FLAG_MOBIL', 'dtype': 'category'},
         {'column_name': 'FLAG_EMP_PHONE', 'dtype': 'category'},
         {'column_name': 'FLAG_WORK_PHONE', 'dtype': 'category'},
         {'column_name': 'OCCUPATION_TYPE', 'dtype': 'category'},
         {'column_name': 'CNT_FAM_MEMBERS', 'dtype': None},
         {'column_name': 'REGION_RATING_CLIENT', 'dtype': 'int'},
         {'column_name': 'ORGANIZATION_TYPE', 'dtype': 'category'},
         {'column_name': 'EXT_SOURCE_1', 'dtype': 'float'},
         {'column_name': 'EXT_SOURCE_2', 'dtype': 'float'},
         {'column_name': 'EXT_SOURCE_3', 'dtype': None},
         {'column_name': 'APARTMENTS_AVG', 'dtype': None},
         {'column_name': 'DAYS_LAST_PHONE_CHANGE', 'dtype': None},
         {'column_name': 'FLAG_DOCUMENT_2', 'dtype': 'category'},
         {'column_name': 'FLAG_DOCUMENT_6', 'dtype': 'category'},
         {'column_name': 'FLAG_DOCUMENT_7', 'dtype': 'category'},
         {'column_name': 'FLAG_DOCUMENT_14', 'dtype': 'category'},
         {'column_name': 'FLAG_DOCUMENT_15', 'dtype': 'category'},
         {'column_name': 'FLAG_DOCUMENT_18', 'dtype': 'category'},
         {'column_name': 'FLAG_DOCUMENT_21', 'dtype': 'category'},
         {'column_name': 'AMT_REQ_CREDIT_BUREAU_YEAR', 'dtype': 'category'}],
     'transformation': [
         {'type': 'series',
          'column_name': 'DAYS_EMPLOYED',
          'action': 'replace',
          'parameters': {'to_replace': 365243},
          'assign': 'DAYS_EMPLOYED'},
         {'type': 'series',
          'column_name': 'DAYS_REGISTRATION',
          'action': 'apply',
          'parameters': {'func': eval('lambda x: np.log1p(np.abs(x))')},
          'assign': 'LOG_DAYS_REGISTRATION'},
         {'type': 'series',
          'column_name': 'DAYS_ID_PUBLISH',
          'action': 'apply',
          'parameters': {'func': eval('lambda x: np.log1p(np.abs(x))')},
          'assign': 'LOG_DAYS_ID_PUBLISH'}]
     },

    {'file': 'data/bureau.csv',
     'features': [
         {'column_name': 'SK_ID_CURR', 'dtype': 'int'},
         {'column_name': 'DAYS_ENDDATE_FACT', 'dtype': None},
         {'column_name': 'AMT_CREDIT_SUM_DEBT', 'dtype': None},
         {'column_name': 'AMT_CREDIT_SUM', 'dtype': None},
         {'column_name': 'AMT_CREDIT_MAX_OVERDUE', 'dtype': None},
         {'column_name': 'CREDIT_DAY_OVERDUE', 'dtype': None},
         {'column_name': 'CNT_CREDIT_PROLONG', 'dtype': None}],
     'transformation': [
         {'type': 'cross-series',
          'column_name': 'AMT_CREDIT_SUM_DEBT',
          'action': 'div',
          'other': 'AMT_CREDIT_SUM',
          'parameters': {'fill_value': 0},
          'assign': 'DEBT_TO_CREDIT'}
     ],
     'aggregation': {
          'groupby': ['SK_ID_CURR'],
          'agg_params': {
               'CREDIT_DAY_OVERDUE': 'mean',
               'SK_ID_CURR': 'count',
               'AMT_CREDIT_MAX_OVERDUE': 'mean',
               'DAYS_ENDDATE_FACT': 'mean',
               'CNT_CREDIT_PROLONG': 'mean',
               'AMT_CREDIT_SUM': 'mean',
               'DEBT_TO_CREDIT': 'mean'},
          'rename': {
              'CREDIT_DAY_OVERDUE': 'AVG_CREDIT_DAY_OVERDUE',
              'SK_ID_CURR': 'CB_RECORD_COUNT',
              'AMT_CREDIT_MAX_OVERDUE': 'AVG_AMT_CREDIT_MAX_OVERDUE',
              'DAYS_ENDDATE_FACT': 'AVG_DAYS_ENDDATE_FACT',
              'CNT_CREDIT_PROLONG': 'AVG_CNT_CREDIT_PROLONG',
              'AMT_CREDIT_SUM': 'AVG_AMT_CREDIT_SUM',
              'DEBT_TO_CREDIT': 'AVG_DEBT_TO_CREDIT'},
          'post_transformation': [
              {'type': 'series',
               'column_name': 'AVG_AMT_CREDIT_MAX_OVERDUE',
               'action': 'fillna',
               'parameters': {'value': 0},
               'assign': 'AVG_AMT_CREDIT_MAX_OVERDUE'}
          ]}
     }

]

DROP_COLS_BEFORE_TRAINING = ['SK_ID_CURR', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH']

LABEL_COLUMN = 'TARGET'


class Model(object):

    __metaclass__ = ABCMeta

    def __init__(self, hparams, pretrained_model=None, trial=0):
        self.hparams = hparams
        self.trial = trial
        print("Model built with hparams %s" % self.hparams)
        if pretrained_model:
            self.model = pretrained_model
        else:
            self.model = None

    @abstractclassmethod
    def train(self, train_dataset, eval_dataset=None, num_round=None, verbose=False):
        print("Start training model")
        raise NotImplementedError()

    @abstractclassmethod
    def val(self, eval_dataset, y_true, threshold=0.5):
        raise NotImplementedError()

    @abstractclassmethod
    def infer(self, test_dataset, threshold=0.5, export=False):
        raise NotImplementedError()


class XGBModel(Model):
    """
    XGBoostModel
    """

    def train(self, train_dataset, eval_dataset=None, num_round=None, verbose=False):
        """

        :param train_X:
        :param train_Y:
        :return:
        """

        eval_dict = {}

        if eval_dataset:
            bst = xgb.train(self.hparams, train_dataset, num_boost_round=num_round, verbose_eval=verbose,
                            early_stopping_rounds=20, evals=eval_dataset, evals_result=eval_dict)
        else:
            bst = xgb.train(self.hparams, train_dataset, num_boost_round=num_round, evals_result=eval_dict, verbose_eval=verbose)

        bst.save_model("xgb_%s.model" % self.trial)

        self.model = bst

        # Output the best store and the respective model
        scores = np.asarray(eval_dict['eval']['auc'])
        best_score = np.max(scores)
        best_model = np.argmax(scores)

        return bst, {'best_score': best_score, 'best_model': best_model}

    def val(self, eval_dataset, y_true, threshold=0.6):

        y_pred = (self.model.predict(eval_dataset, ntree_limit=self.model.best_iteration) > threshold).astype(int)
        y_true = y_true.as_matrix()

        print(accuracy_score(y_true, y_pred))
        print(confusion_matrix(y_true, y_pred))

    def infer(self, test_dataset, threshold=0.5, export=False):

        y_pred = (self.model.predict(test_dataset, ntree_limit=self.model.best_iteration) > threshold).astype(int)

        if export:
            print(y_pred)

        return y_pred


class RandomForestModel(Model):

    def train(self, train_dataset, eval_dataset=None, num_round=None, verbose=False):
        print("Start training model")
        raise NotImplementedError()

    def val(self, eval_dataset, y_true, threshold=0.5):
        raise NotImplementedError()

    def infer(self, test_dataset, threshold=0.5, export=False):
        raise NotImplementedError()


def generate_params_set(model='xgb', num_trials=2):

    if model == 'xgb':

        trials = []

        # Generate n trials
        for i in range(num_trials):

            XGB_HPARAMS = {
                'max_depth': np.random.randint(1, 20),
                'min_child_weight': np.random.randint(5, 12),
                'gamma': np.power(2, np.random.randint(4)),
                'eta': np.round(np.random.uniform(low=0.5), decimals=2),
                'objective': 'binary:logistic',
                'nthread': 4,
                'eval_metric': 'auc',
                'silent': 1
            }

            trials.append(XGB_HPARAMS)

        return trials


def train():
    # Load the file
    merged_features, target = load_data(FEATURE_FILE_LIST, set_index='SK_ID_CURR')

    # print(merged_features.info())

    # Split dataset
    X_train, X_val, y_train, y_val = split_data(merged_features, target)

    # Transform the dataset for xgb
    dtrain = xgb.DMatrix(X_train, label=y_train)
    deval = xgb.DMatrix(X_val, label=y_val)

    evallist = [(deval, 'eval'), (dtrain, 'train')]

    # Generate hyperparameters
    hparams_set = generate_params_set('xgb', num_trials=30)

    best_scores = []
    best_round = []

    # Build model for each hparams set
    for i, hparam in enumerate(hparams_set):

        model = XGBModel(hparam, trial=i)
        bst, scores_dict = model.train(train_dataset=dtrain, eval_dataset=evallist, num_round=20, verbose=True)

        best_scores.append(scores_dict)
        best_round.append(bst.best_iteration)

        model.val(eval_dataset=deval, y_true=y_val)

    print("Exporting result...")
    print(best_scores)

    result = pd.DataFrame.from_dict(hparams_set)
    scores_df = pd.DataFrame.from_dict(best_scores)
    result = pd.concat([result, scores_df], axis=1)

    result.to_csv("result.csv")


if __name__ == "__main__":
    train()